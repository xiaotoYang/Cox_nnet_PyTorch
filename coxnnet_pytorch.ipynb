{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73aa857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e23de8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a1fe8",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "14ffed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coxnnet(nn.Module):\n",
    "    def __init__(self, input_dim, n_hidden):\n",
    "        super(Coxnnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, n_hidden)\n",
    "        self.fc2 = nn.Linear(n_hidden, 1, bias = False)\n",
    "        self.selu = nn.SELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.selu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07c07e",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "687c721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coxnnet_Dataset(Dataset):\n",
    "    def __init__(self, data, survival_time, event):\n",
    "        self.data = torch.from_numpy(data).float()  # Convert data to torch tensor\n",
    "        self.survival_time = torch.from_numpy(survival_time).float()\n",
    "        self.event = torch.from_numpy(event).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        survival_time = self.survival_time[idx]\n",
    "        event = self.event[idx]\n",
    "        return sample, survival_time, event\n",
    "    \n",
    "def cox_ph_loss(risks, time, event):\n",
    "    \"\"\"\n",
    "    Compute Cox proportional hazards loss per sample\n",
    "    :param risks: The output from the Cox-PH layer (log hazard ratios).\n",
    "    :param time: Observed times (either event or censoring time).\n",
    "    :param event: Event indicator (1 if event occurred, 0 if censored).\n",
    "    :return: Negative log partial likelihood.\n",
    "    \"\"\"\n",
    "    # Sort the individuals by descending survival time\n",
    "    eps = 1e-100\n",
    "    time = time + eps*torch.ones(len(time))# ensure all times are positive\n",
    "    risk_order = torch.argsort(time, descending=True)\n",
    "    risks = risks[risk_order]\n",
    "    event = event[risk_order]\n",
    "\n",
    "    # Compute the risk score exp(log hazard ratio) for all\n",
    "    hazard_ratios = torch.exp(risks)\n",
    "\n",
    "    # Calculate the cumulative hazard at each actual event\n",
    "    log_cumulative_hazard = torch.log(torch.cumsum(hazard_ratios, dim=0))\n",
    "    observed_log_hazard = risks - log_cumulative_hazard\n",
    "\n",
    "    # Only include the cases where an event occurred\n",
    "    uncensored_likelihood = observed_log_hazard * event\n",
    "    return -torch.sum(uncensored_likelihood) / torch.sum(event)\n",
    "\n",
    "def negative_log_likelihood(theta, ystatus):\n",
    "    exp_theta = torch.exp(theta.squeeze(-1))\n",
    "    risk = torch.cumsum(exp_theta.flip(dims=[0]), dim=0).flip(dims=[0])\n",
    "    log_risk = torch.log(risk)\n",
    "    log_likelihood = (theta - log_risk) * ystatus\n",
    "    return -torch.mean(log_likelihood)\n",
    "\n",
    "def Xavier_unif_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "def scale(matrix):\n",
    "    min_val = np.min(matrix)\n",
    "    max_val = np.max(matrix)\n",
    "    scaled_matrix = (matrix - min_val) / (max_val - min_val)\n",
    "    return scaled_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb16d49",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "04160b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cox_model(model, train_dataloader, valid_dataloader, learning_rate, l2_penalty, epochs, min_delta = 1e-4, \n",
    "                    patience = 10):\n",
    "    \n",
    "    #adam optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay= l2_penalty)\n",
    "    #early stopping vars\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    c = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            X_batch, time, event = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = cox_ph_loss(outputs, time, event)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "        if epoch%1 == 0:\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            y_pred = np.array([])\n",
    "            time = np.array([])\n",
    "            event = np.array([])\n",
    "            with torch.no_grad():\n",
    "                for batch in valid_dataloader:\n",
    "                    X_val, time_val, event_val = batch\n",
    "                    val_outputs = model(X_val)\n",
    "                    val_loss += cox_ph_loss(val_outputs, time_val, event_val).item()\n",
    "                    val_outputs, time_val,event_val = torch.squeeze(val_outputs), torch.squeeze(time_val), torch.squeeze(event_val)\n",
    "                    y_pred = np.append(y_pred, np.array(val_outputs))\n",
    "                    time = np.append(time, np.array(time_val))\n",
    "                    event = np.append(event, np.array(event_val))\n",
    "\n",
    "            avg_val_loss = val_loss / len(valid_dataloader)\n",
    "            concordance = concordance_index(time, -y_pred, event_observed = event)\n",
    "            if concordance > c:\n",
    "                c = concordance\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.10f}, Val Loss: {avg_val_loss:.10f}, C-index: {concordance:.10f}\")\n",
    "            \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_val_loss < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_val_loss\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_val_loss > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_val_loss \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        print(\"is best model:\", is_best_model)\n",
    "    print(\"max validation c-index: \", c)\n",
    "    return best_model, [time, y_pred, event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6752c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Model(model, test_dataloader):\n",
    "    '''\n",
    "    Test the model\n",
    "    '''\n",
    "    output_last = True\n",
    "    losses_ppl = []\n",
    "    cindex_test = []\n",
    "    print('start test')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, survival_time, event in test_dataloader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            event = event.float().to(device)\n",
    "            survival_time = survival_time.float().to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs_squeezed, survival_time_squeezed,event_squeezed = torch.squeeze(outputs), torch.squeeze(survival_time), torch.squeeze(event)\n",
    "            loss_ppl = cox_ph_loss(outputs_squeezed, survival_time_squeezed,event_squeezed)\n",
    "        \n",
    "            cindex= concordance_index(survival_time, -outputs, event_observed=event)\n",
    "            #print(torch.squeeze(event), torch.squeeze(outputs))\n",
    "                \n",
    "            losses_ppl.append(loss_ppl.data)\n",
    "            cindex_test.append(cindex)\n",
    "            \n",
    "        print(cindex_test)\n",
    "        print('Tested: mean_loss:{}, std_loss:{}, cindex:{}, std_cindex:{}'.format(np.mean(losses_ppl), np.std(losses_ppl), np.mean(cindex_test), np.std(cindex_test)))\n",
    "                                                                                                                                \n",
    "    return [losses_ppl, cindex_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "3e7953f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = \"/home/path/\"\n",
    "folder = \"/folder/path/\"\n",
    "i = \"3\"\n",
    "X_train_val = np.loadtxt(home+folder+\"x_train\"+i+\".csv\", skiprows = 1, delimiter = \",\")\n",
    "y_train_val = np.loadtxt(home+folder+\"ytime_train\"+i+\".csv\", skiprows = 1, delimiter = \",\")\n",
    "event_train_val = np.loadtxt(home+folder+\"ystatus_train\"+i+\".csv\", skiprows = 1, delimiter = \",\")\n",
    "X_test = np.loadtxt(home+folder+\"x_test\"+i+\".csv\", skiprows = 1, delimiter = \",\")\n",
    "y_test = np.loadtxt(home+folder+\"ytime_test\"+i+\".csv\", skiprows = 1, delimiter = \",\")\n",
    "event_test = np.loadtxt(home+folder+\"ystatus_test\"+i+\".csv\", skiprows = 1, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d332eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 20\n",
    "X_train, X_val, y_train, y_val, event_train, event_val = train_test_split(X_train_val, y_train_val, event_train_val, \n",
    "                                                                          test_size=0.20, random_state=random_state)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548227dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    BATCH_SIZE = 64\n",
    "    num_epochs = 50\n",
    "    patience = 10\n",
    "    min_delta = 0.0001 \n",
    "    learning_rate = 0.01\n",
    "    dropout = 0.9\n",
    "    l2_penalty = 1e-1\n",
    "\n",
    "    #device config\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_dataset = Coxnnet_Dataset(X_train, y_train, event_train)\n",
    "    valid_dataset = Coxnnet_Dataset(X_val, y_val, event_val)\n",
    "    test_dataset = Coxnnet_Dataset(X_test, y_test, event_test)\n",
    "\n",
    "    # Create data loaders for our datasets; shuffle for training, not for validation\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = 512, shuffle=False)\n",
    "    \n",
    "    inputs, survival, event = next(iter(train_dataloader))\n",
    "    [batch_size, fea_size] = inputs.size()\n",
    "    hidden_size = np.ceil(np.sqrt(fea_size)).astype(int)\n",
    "    print(hidden_size)\n",
    "    \n",
    "    model = Coxnnet(input_dim = fea_size, n_hidden=hidden_size)\n",
    "    #model.apply(Xavier_unif_init)\n",
    "    best_model, val_pred = train_cox_model(model, train_dataloader, valid_dataloader, learning_rate, l2_penalty, \n",
    "                                           epochs=num_epochs, min_delta = min_delta, patience = patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945c87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[losses_ppl, cindex_test] = Test_Model(best_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7f06176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(home+folder+\"pytorch_coxnnet_cv_cindex\"+i+\".csv\", cindex_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
